{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philosophy-question-answerer/model-tests-automated/blob/main/model_tests_automated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3fbfhCxDoS"
      },
      "source": [
        "# Package Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwl7_upUxDoT"
      },
      "outputs": [],
      "source": [
        "! pip install cohere\n",
        "! pip install ctransformers\n",
        "! pip install faiss-cpu\n",
        "! pip install huggingface_hub\n",
        "! pip install langchain\n",
        "! pip install sentence-transformers\n",
        "! pip install transformers\n",
        "! pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set-up Weights and Biases"
      ],
      "metadata": {
        "id": "AVMXfafRQ1VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init()"
      ],
      "metadata": {
        "id": "zI86rsenkjEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngIxudooxDoU"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAMlj-NFxDoU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import textwrap\n",
        "\n",
        "from torch import cuda\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from ctransformers import AutoModelForCausalLM\n",
        "import cohere\n",
        "\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "from google.colab import userdata, drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBUayTW_Y4gm"
      },
      "source": [
        "# Set Up Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzlZ7NVIY9VM"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "# ! mkdir -p '/content/drive/My Drive/Model Tests Results'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnjVWk7cxDoU"
      },
      "source": [
        "# Environment & Global Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT2lfy4T5z4h"
      },
      "source": [
        "## API Keys & Third Party Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIOtGRAnxDoV"
      },
      "outputs": [],
      "source": [
        "COHERE_API_KEY = userdata.get('COHERE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O514EBoy5xFc"
      },
      "source": [
        "## Chunking Parameters Combinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfMYdCzU5pUf"
      },
      "outputs": [],
      "source": [
        "chunk_parameter_combinations = [\n",
        "    {'chunk_size': 512, 'chunk_overlap': 50},\n",
        "    {'chunk_size': 512, 'chunk_overlap': 100},\n",
        "    {'chunk_size': 1024, 'chunk_overlap': 100},\n",
        "    {'chunk_size': 1024, 'chunk_overlap': 150},\n",
        "    {'chunk_size': 1500, 'chunk_overlap': 100},\n",
        "    {'chunk_size': 1500, 'chunk_overlap': 300},\n",
        "    {'chunk_size': 2048, 'chunk_overlap': 200},\n",
        "    {'chunk_size': 2048, 'chunk_overlap': 350}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H3VhHKR6Tlw"
      },
      "source": [
        "## Models To Be Tested"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxO1kQS76UDZ"
      },
      "outputs": [],
      "source": [
        "models_dict = {\n",
        "    'Mistral_7B_Instruct_v0p1': {\n",
        "        'model_path_or_repo_id': 'TheBloke/Mistral-7B-Instruct-v0.1-GGUF',\n",
        "        'model_file': 'mistral-7b-instruct-v0.1.Q5_K_M.gguf',\n",
        "        'model_type': 'mistral',\n",
        "    },\n",
        "    'Mistral_7B_Instruct_v0p2': {\n",
        "        'model_path_or_repo_id': 'TheBloke/Mistral-7B-Instruct-v0.2-GGUF',\n",
        "        'model_file': 'mistral-7b-instruct-v0.2.Q5_K_M.gguf',\n",
        "        'model_type': 'mistral',\n",
        "    },\n",
        "    'Llama_2_7b_Chat': {\n",
        "        'model_path_or_repo_id': 'TheBloke/Llama-2-7b-Chat-GGUF',\n",
        "        'model_file': 'llama-2-7b-chat.Q5_K_M.gguf',\n",
        "        'model_type': 'llama',\n",
        "    },\n",
        "    'Llama_2_13B_chat': {\n",
        "        'model_path_or_repo_id': 'TheBloke/Llama-2-13B-chat-GGUF',\n",
        "        'model_file': 'llama-2-13b-chat.Q5_K_M.gguf',\n",
        "        'model_type': 'llama',\n",
        "    },\n",
        "    'SOLAR_10p7B_Instruct_v1p0': {\n",
        "        'model_path_or_repo_id': 'TheBloke/SOLAR-10.7B-Instruct-v1.0-GGUF',\n",
        "        'model_file': 'solar-10.7b-instruct-v1.0.Q5_K_M.gguf',\n",
        "        'model_type': 'solar',\n",
        "    },\n",
        "    'orca_mini_v3_7B': {\n",
        "        'model_path_or_repo_id': 'TheBloke/orca_mini_v3_7B-GGUF',\n",
        "        'model_file': 'orca_mini_v3_7b.Q5_K_M.gguf',\n",
        "        'model_type': 'llama',\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_WWUQwd56-q"
      },
      "source": [
        "## Test Philosophy Questions â€” Ludwig Wittgenstein's *Philosophical Investigations*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-egPLcH6HsV"
      },
      "outputs": [],
      "source": [
        "TEST_QUESTIONS = [\n",
        "    'What determines the meaning of a word?',\n",
        "    'When can something can be classified as a game?',\n",
        "    'What is the concept of family resemblance?',\n",
        "    'Is the existence of a private language possible?',\n",
        "    'What does following a rule entail?',\n",
        "    'Can the concept of sameness be used to teach a rule?',\n",
        "    'What is the role of language-games?',\n",
        "    'How is the idea that mental processes form the basis of our understanding of language critiqued?',\n",
        "    'Do private mental objects exist?',\n",
        "    'What is the relationship between forms of life and language?',\n",
        "    'How is it explained that the meaning of a word is its use in language?',\n",
        "    'How do philosophical problems arise from misunderstandings of language?',\n",
        "    'What is problematic about the Augustinian view on meaning?',\n",
        "    'What is said about the misguided nature of philosophical questions?',\n",
        "    'What is the purpose of the analogy with the toolbox?',\n",
        "    'In what ways does the notion of \\'language-games\\' challenge traditional epistemology?',\n",
        "    'What implications does the critique of private language have for theories of consciousness?',\n",
        "    'How is the concept of pain used to argue against the possibility of a private language?',\n",
        "    'In what ways does the examination of pain\\'s sameness challenge the understanding of subjective experiences?',\n",
        "    'What are the limitations of language?',\n",
        "    'What is the relationship between forms of life and understanding philosophy?'\n",
        "]\n",
        "print(len(TEST_QUESTIONS))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNIXPz1dxDoV"
      },
      "source": [
        "# Loading the Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnejRPMkxDoV"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "\n",
        "  dataset_path = '/content/drive/My Drive/Dataset'\n",
        "\n",
        "  files = os.listdir(dataset_path)\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  for file in files:\n",
        "      if file.endswith('.txt'):\n",
        "          file_path = os.path.join(dataset_path, file)\n",
        "\n",
        "          loader = TextLoader(file_path, encoding='UTF-8')\n",
        "          document = loader.load()\n",
        "\n",
        "          documents.append(document)\n",
        "\n",
        "  print(f'Loaded {len(documents)} documents.')\n",
        "\n",
        "  return documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgeKdzFjxDoW"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i1dbuE7xDoW"
      },
      "source": [
        "## Create Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D_RJ9SWxDoW"
      },
      "outputs": [],
      "source": [
        "def create_chunks(documents, chunk_size=750, chunk_overlap=50):\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size,\n",
        "                                                   chunk_overlap=chunk_overlap,\n",
        "                                                   separators=['\\n\\n', '\\n', '.', ' ', ''])\n",
        "    all_chunks = []\n",
        "\n",
        "    for document in documents:\n",
        "        chunks = text_splitter.split_documents(document)\n",
        "        all_chunks.extend(chunks)\n",
        "\n",
        "    print(f'Chunks successfully created. Number of chunks = {len(all_chunks)}')\n",
        "\n",
        "    return all_chunks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = load_dataset()\n",
        "chunks = create_chunks(docs)"
      ],
      "metadata": {
        "id": "52AwLgxtQmIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks[0].metadata['author'] = 'xyz'\n",
        "chunks[0].metadata['title'] = 'xyz'\n",
        "c = chunks[0].metadata\n",
        "print(c)"
      ],
      "metadata": {
        "id": "V0bCttCSSLVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCSkc0YxxDoX"
      },
      "source": [
        "## Load Model Locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogZ85Nt9xDoX"
      },
      "outputs": [],
      "source": [
        "def load_model_locally(model_choice):\n",
        "\n",
        "    return AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=model_choice['model_path_or_repo_id'],\n",
        "                                                model_file=model_choice['model_file'],\n",
        "                                                model_type=model_choice['model_type'],\n",
        "                                                gpu_layers=64,\n",
        "                                                context_length=6200\n",
        "                                                )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ffKCP93xDoY"
      },
      "source": [
        "## Query Cohere Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PJB133PxDoY"
      },
      "outputs": [],
      "source": [
        "co = cohere.Client(COHERE_API_KEY)\n",
        "\n",
        "def query_cohere(prompt):\n",
        "    response = co.chat(message=prompt, model='command', temperature=0.9)\n",
        "    return response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OoL2xkExDoY"
      },
      "source": [
        "\n",
        "## Save Results to .txt File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ah_3PvGbxDoY"
      },
      "outputs": [],
      "source": [
        "results_dir = '/content/drive/My Drive/Model Tests Results'\n",
        "\n",
        "def save_results_to_txt(result_string, model_name, chunk_size, chunk_overlap, is_reranking):\n",
        "\n",
        "    output_file_path = f'{results_dir}/{model_name}_{chunk_size}_{chunk_overlap}_{is_reranking}.txt'\n",
        "\n",
        "    with open(output_file_path, 'a', encoding='utf-8') as file:\n",
        "        file.write(f'{result_string}\\n')\n",
        "\n",
        "def add_headings():\n",
        "    for model in tqdm(models_dict, desc='Models'):\n",
        "        for combination in tqdm(chunk_parameter_combinations, desc='Chunking Combinations'):\n",
        "\n",
        "            chunk_size = combination['chunk_size']\n",
        "            chunk_overlap = combination['chunk_overlap']\n",
        "\n",
        "            for is_reranking in tqdm([True, False], desc='Reranking'):\n",
        "                output_file_path = f'{results_dir}/{model}_{chunk_size}_{chunk_overlap}_{is_reranking}.txt'\n",
        "\n",
        "\n",
        "                with open(output_file_path, 'r', encoding='utf-8') as file:\n",
        "                    original_content = file.read()\n",
        "\n",
        "                with open(output_file_path, 'w', encoding='utf-8') as file:\n",
        "                    file.write(f'\\nModel = {model}\\n')\n",
        "                    file.write(f'Chunk Size = {chunk_size}\\n')\n",
        "                    file.write(f'Chunk Overlap = {chunk_overlap}\\n')\n",
        "                    file.write(f'Reranking on = {is_reranking}\\n\\n')\n",
        "                    file.write(original_content)\n",
        "\n",
        "    print(f'Successfully added all headings.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_oU8zbmxDoZ"
      },
      "source": [
        "\n",
        "## Format Question-Context-Answer (QCA) String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiRlVenvxDoZ"
      },
      "outputs": [],
      "source": [
        "def format_qca_string(new_question, new_context, new_answer, inference_time):\n",
        "    return f'''\n",
        "#######################\\n\\n\n",
        "\n",
        "QUESTION:\\n\n",
        "{new_question}\\n\\n\n",
        "\n",
        "CONTEXT:\\n\n",
        "{new_context}\\n\\n\n",
        "\n",
        "ANSWER:\\n\n",
        "{new_answer}\\n\\n\n",
        "\n",
        "INFERENCE_TIME:\\n\n",
        "{inference_time} seconds = {inference_time/60} minutes\\n\\n\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L79BCh1OxDoZ"
      },
      "source": [
        "# Creating Vector Database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuDlRUZjxDoZ"
      },
      "source": [
        "## Load the Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQ6dpDCmxDoZ"
      },
      "outputs": [],
      "source": [
        "embedding_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=embedding_model_id,\n",
        "    model_kwargs={'device': device},\n",
        "    encode_kwargs={'device': device, 'batch_size': 10}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xNr_dydxDoZ"
      },
      "source": [
        "## Create, Populate, Save, and Load FAISS Indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWU8EP55dD5e"
      },
      "outputs": [],
      "source": [
        "FAISS_INDICES_PATH = '/content/drive/My Drive/FAISS Indices'\n",
        "\n",
        "def make_faiss_index_name(chunk_size, chunk_overlap):\n",
        "  return f'ChunkSize_{chunk_size}_ChunkOverlap_{chunk_overlap}'\n",
        "\n",
        "def create_populate_and_save_faiss_index(index_name, chunks, embedding_model):\n",
        "  faiss_index = FAISS.from_documents(chunks, embedding_model)\n",
        "  faiss_index.save_local(f'{FAISS_INDICES_PATH}/{index_name}')\n",
        "\n",
        "def load_faiss_index(index_name, embedding_model):\n",
        "  return FAISS.load_local(f'{FAISS_INDICES_PATH}/{index_name}', embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY5lSsKBxDoa"
      },
      "source": [
        "## Querying the Database (Semantic Search)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB6kD9u4fEbS"
      },
      "outputs": [],
      "source": [
        "def semantic_search(faiss_index, question, num_matched_excerpts):\n",
        "\n",
        "  results = faiss_index.similarity_search(query=question, k=num_matched_excerpts)\n",
        "\n",
        "  docs = [\n",
        "    {\n",
        "      'text': result.page_content,\n",
        "      'source': result.metadata['source']\n",
        "    } for result in results\n",
        "  ]\n",
        "\n",
        "  return docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUdOmftmxDoa"
      },
      "source": [
        "# Reranking (Cohere API)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHe_j23NjoQl"
      },
      "outputs": [],
      "source": [
        "def semantic_search_reranking(faiss_index, question, num_matched_excerpts, num_reranked_excerpts):\n",
        "    docs = semantic_search(faiss_index=faiss_index, question=question, num_matched_excerpts=num_matched_excerpts)\n",
        "    text_to_source = { doc['text'] : doc['source'] for doc in docs }\n",
        "    reranked_docs = co.rerank(query=question,\n",
        "                             documents=[ doc['text'] for doc in docs ],\n",
        "                             top_n=num_reranked_excerpts,\n",
        "                             model='rerank-english-v2.0')\n",
        "    reranked_texts = [ doc.document['text'] for doc in reranked_docs ]\n",
        "\n",
        "    docs = [\n",
        "        {\n",
        "          'text': text,\n",
        "          'source': text_to_source[text]\n",
        "        } for text in reranked_texts\n",
        "    ]\n",
        "\n",
        "    return docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS01qGbZxDoa"
      },
      "source": [
        "# Retrieval Augmented Generation (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEuB6Ny6xDoa"
      },
      "source": [
        "## Create the Question-Context Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2q1KZxcqI3x"
      },
      "outputs": [],
      "source": [
        "def extract_context(faiss_index, question, num_matched_excerpts, is_reranking, num_reranked_excerpts):\n",
        "\n",
        "    if is_reranking:\n",
        "        docs = semantic_search_reranking(faiss_index=faiss_index,\n",
        "                                         question=question,\n",
        "                                         num_matched_excerpts=num_matched_excerpts,\n",
        "                                         num_reranked_excerpts=num_reranked_excerpts\n",
        "                                         )\n",
        "    else:\n",
        "        docs = semantic_search(faiss_index=faiss_index, question=question, num_matched_excerpts=num_reranked_excerpts)\n",
        "\n",
        "    context = ''\n",
        "    for doc in docs:\n",
        "        context = context + textwrap.fill(doc['text'], 150) + '\\n' + textwrap.fill(doc['source'], 150) + '\\n\\n'\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBdg-7WyxDob"
      },
      "outputs": [],
      "source": [
        "def create_prompt(question, context):\n",
        "\n",
        "  prompt = f'''\n",
        "  Answer the following QUESTION with the given CONTEXT. \\n\\n\n",
        "  QUESTION: {question} \\n\n",
        "  CONTEXT: \\n {context} \\n\n",
        "  ANSWER:\n",
        "  '''\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lYJxKIUkBV2"
      },
      "source": [
        "# FAISS Indices Creation for Every Chunk Parameters Combination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1XhaI30kA2q"
      },
      "outputs": [],
      "source": [
        "def create_faiss_indices(documents, embedding_model):\n",
        "  for combination in tqdm(chunk_parameter_combinations, desc='Chunk Parameter Combinations'):\n",
        "\n",
        "    chunk_size = combination['chunk_size']\n",
        "    chunk_overlap = combination['chunk_overlap']\n",
        "\n",
        "    print(f'\\nProcessing combination: Chunk Size = {chunk_size}, Chunk Overlap = {chunk_overlap}')\n",
        "\n",
        "    chunks = create_chunks(documents, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "\n",
        "    index_name = make_faiss_index_name(chunk_size, chunk_overlap)\n",
        "\n",
        "    print(f'Creating {index_name} index.')\n",
        "\n",
        "    start_time = time.time()\n",
        "    create_populate_and_save_faiss_index(index_name=index_name, chunks=chunks, embedding_model=embedding_model)\n",
        "    end_time = time.time()\n",
        "\n",
        "    index_creation_time = (end_time - start_time)/60\n",
        "\n",
        "    print(f'{index_name} index was successfully created in {index_creation_time} minutes.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOh0_HRkne35"
      },
      "outputs": [],
      "source": [
        "# documents = load_dataset()\n",
        "# create_faiss_indices(documents, embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODSaPrWjxDob"
      },
      "source": [
        "# Model Tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bKErueRH8OR"
      },
      "source": [
        "## Load All Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0u0_RGLHqTI"
      },
      "outputs": [],
      "source": [
        "loaded_models = {model_name: load_model_locally(models_dict[model_name]) for model_name in models_dict}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLpPMufIH91j"
      },
      "source": [
        "## Run Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPiLDDb-xDob"
      },
      "outputs": [],
      "source": [
        "for combination in tqdm(chunk_parameter_combinations, desc='Chunking Combinations'):\n",
        "\n",
        "    chunk_size = combination['chunk_size']\n",
        "    chunk_overlap = combination['chunk_overlap']\n",
        "\n",
        "    index_name = make_faiss_index_name(chunk_size, chunk_overlap)\n",
        "    index = load_faiss_index(index_name,embedding_model=embedding_model)\n",
        "\n",
        "    print(f'Loaded {index_name} index.')\n",
        "\n",
        "    for is_reranking in tqdm([True, False], desc='Reranking'):\n",
        "\n",
        "        print(f'Processing combination: Chunk Size = {chunk_size}, Chunk Overlap = {chunk_overlap}, Reranking = {is_reranking}')\n",
        "\n",
        "        for question in tqdm(TEST_QUESTIONS, desc='Test Questions'):\n",
        "\n",
        "          question_number = TEST_QUESTIONS.index(question) + 1\n",
        "          print(f'Querying question {question_number}')\n",
        "\n",
        "          context = extract_context(faiss_index = index,\n",
        "                                    question=question,\n",
        "                                    num_matched_excerpts=25,\n",
        "                                    is_reranking=is_reranking,\n",
        "                                    num_reranked_excerpts=3)\n",
        "\n",
        "          prompt = create_prompt(question=question, context=context)\n",
        "\n",
        "          for model in tqdm(loaded_models, desc='Models'):\n",
        "\n",
        "            print(f'Querying model {model}')\n",
        "\n",
        "            result_string = ''\n",
        "\n",
        "            start_time = time.time()\n",
        "\n",
        "            answer = loaded_models[model](prompt)\n",
        "\n",
        "            end_time = time.time()\n",
        "            inference_time = (end_time - start_time)\n",
        "\n",
        "            print(f'Question {question_number} was answered in {inference_time} seconds = {inference_time/60} minutes.')\n",
        "\n",
        "            result_string += format_qca_string(new_question=question,\n",
        "                                               new_context=context,\n",
        "                                               new_answer=answer,\n",
        "                                               inference_time=inference_time)\n",
        "\n",
        "            save_results_to_txt(result_string=result_string,\n",
        "                                model_name=model,\n",
        "                                chunk_size=chunk_size,\n",
        "                                chunk_overlap=chunk_overlap,\n",
        "                                is_reranking=is_reranking)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "add_headings()"
      ],
      "metadata": {
        "id": "-1JR9FsXLw3m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "O514EBoy5xFc"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "deepnote_execution_queue": [],
    "deepnote_full_width": true,
    "deepnote_notebook_id": "c4f7f37be5c6444e99d25711c7e1d018",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}